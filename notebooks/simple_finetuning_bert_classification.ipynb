{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "involved-hartford",
   "metadata": {},
   "source": [
    "# Ingesting Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "classified-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from nlp import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingest tweets from the Kaggle disaster tweet competition: https://www.kaggle.com/c/nlp-getting-started\n",
    "\n",
    "tweets = pd.read_csv('../data/disaster.csv')\n",
    "\n",
    "print(tweets.shape)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exclusive-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ebc8fa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of tweet lengths. I don't love the left skewed data\n",
    "\n",
    "tweets['text'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitted-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets['id']\n",
    "del tweets['keyword']\n",
    "del tweets['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-brunswick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blank-county",
   "metadata": {},
   "source": [
    "# Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "after-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "URL_REGEX = re.compile('http(s)?:\\/\\/t.co\\/\\w+')\n",
    "MENTION_REGEX = re.compile('@\\w+')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # remove mentions, the pound sign, and replace urls with URL token\n",
    "    tweet = re.sub(URL_REGEX, 'url', tweet)  # replace urls with url. Assumes that the mention of a url is significant\n",
    "    tweet = re.sub(MENTION_REGEX, '', tweet)  # remove mentions entirely\n",
    "    tweet = tweet.replace('#', '')  # remove pound signs\n",
    "    \n",
    "    return tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerous-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEG issues Hazardous Weather Outlook (HWO) url'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet('@prof_oz MEG issues Hazardous #Weather Outlook (HWO) http://t.co/3X6RBQJHn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-record",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dietary-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>The out of control wild fires in California ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this earthquake Ma...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive wildfires evacuation ord...       1\n",
       "4     Just got sent this photo from Ruby Alaska as s...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  The out of control wild fires in California ev...       1\n",
       "7610     M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'] = tweets['text'].apply(clean_tweet)\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8961ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ecb3a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7178d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rental-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ef09180>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of tweet lengths after cleaning. Much more normal :)\n",
    "\n",
    "tweets['text'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "statutory-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trainer is expecting a 'label' (see the forward method in the docs)\n",
    "tweets['label'] = tweets['target']\n",
    "del tweets['target']\n",
    "\n",
    "tweet_dataset = Dataset.from_pandas(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51520718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>The out of control wild fires in California ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Our Deeds are the Reason of this earthquake Ma...      1\n",
       "1                Forest fire near La Ronge Sask. Canada      1\n",
       "2     All residents asked to 'shelter in place' are ...      1\n",
       "3     13,000 people receive wildfires evacuation ord...      1\n",
       "4     Just got sent this photo from Ruby Alaska as s...      1\n",
       "...                                                 ...    ...\n",
       "7608  Two giant cranes holding a bridge collapse int...      1\n",
       "7609  The out of control wild fires in California ev...      1\n",
       "7610     M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url      1\n",
       "7611  Police investigating after an e-bike collided ...      1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...      1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "twelve-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = 'bert-base-uncased'  # uncased will lowercase everything and remove accents\n",
    "\n",
    "# reminder uncased vs cased. We are using uncased to simplify and we don't think case will matter here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "furnished-specification",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6eec3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7632, 102], [101, 7592, 2045, 102]], 'token_type_ids': [[0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(['hi', 'hello there'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae13378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7632, 102, 0], [101, 7592, 2045, 102]], 'token_type_ids': [[0, 0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 0], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(['hi', 'hello there'], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32c8e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[PAD]', 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.pad_token, bert_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2132392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7632"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.vocab['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intermediate-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21954465f4c4619bd16e908d29b7e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simple function to batch tokenize utterances with truncation\n",
    "def preprocess_function(examples):\n",
    "    return bert_tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tweet_dataset = tweet_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "willing-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90444190aac947cc94b117dcd7815dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cad6fc4a8784b119dbae975363004dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset has a built in train test split method\n",
    "tweet_dataset = tweet_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab5c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 6090),\n",
       " 'test': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 1523)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9061f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset.remove_column_('text')  # remove the text column because we don't need to keep it in memory anymore\n",
    "# this is not required but speeds things up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "932cf16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset(features: {'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 6090),\n",
       " 'test': Dataset(features: {'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 1523)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "involved-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7c6ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'input_ids': [101,\n",
       "  7752,\n",
       "  11484,\n",
       "  26436,\n",
       "  6613,\n",
       "  6840,\n",
       "  1057,\n",
       "  2080,\n",
       "  2678,\n",
       "  24471,\n",
       "  2140,\n",
       "  24471,\n",
       "  2140,\n",
       "  102],\n",
       " 'label': 1,\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdd874f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] sinkhole swallows brooklyn intersection uo video url url [SEP]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(tweet_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bdc87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[  101,  7752, 11484, 26436,  6613,  6840,  1057,  2080,  2678, 24471,\n",
       "          2140, 24471,  2140,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  4633, 19939,  2005,  6504,  1037,  1059, 11961,  2140, 11101,\n",
       "          2003,  2746,  1012,  1012,  1012,  1016,  2244, 24471,  2140,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2293, 12701,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  1012,  1012,  1012,  1045,  2453,  4965,  2026,  9686,\n",
       "         29112,  5195,  2005, 28625, 21197,  2937,  1012,  1012,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2331,  2006,  2737,  2650,  1024,  2339, 15811,  3685,  2202,\n",
       "          2035,  1996,  7499,  1029,  1024,  4315, 12502,  3672,  2003,  2025,\n",
       "          2200,  2691,  1012,  2197,  2095,  2625, 16215,  1012,  1012,  1012,\n",
       "         24471,  2140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1, 0, 0, 1])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(tweet_dataset['train'][:5])\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b090b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "715aeab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask']  # 1's where we have tokens we care about and 0 where we don't want to calculate attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf91c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7752, 11484, 26436,  6613,  6840,  1057,  2080,  2678, 24471,\n",
       "          2140, 24471,  2140,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  4633, 19939,  2005,  6504,  1037,  1059, 11961,  2140, 11101,\n",
       "          2003,  2746,  1012,  1012,  1012,  1016,  2244, 24471,  2140,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2293, 12701,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  1012,  1012,  1012,  1045,  2453,  4965,  2026,  9686,\n",
       "         29112,  5195,  2005, 28625, 21197,  2937,  1012,  1012,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2331,  2006,  2737,  2650,  1024,  2339, 15811,  3685,  2202,\n",
       "          2035,  1996,  7499,  1029,  1024,  4315, 12502,  3672,  2003,  2025,\n",
       "          2200,  2691,  1012,  2197,  2095,  2625, 16215,  1012,  1012,  1012,\n",
       "         24471,  2140,   102]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']  # token ids are padded at the end with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "158db512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] sinkhole swallows brooklyn intersection uo video url url [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(batch['input_ids'][0])  # see the pad tokens. 0 --> [PAD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b541a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "smoking-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "sequence_classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, \n",
    "    num_labels=2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "sequence_classification_model.config.id2label = {0: 'NOT DISASTER', 1: 'DISASTER'}\n",
    "\n",
    "sequence_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "instrumental-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/9xqbqkg90tnc0cmm0dxt985m0000gn/T/ipykernel_71109/676540184.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stupid-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./clf/results',\n",
    "    logging_dir='./clf/logs',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=1,\n",
    "    save_strategy='epoch',\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tweet_dataset['train'],\n",
    "    eval_dataset=tweet_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a3979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 04:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.714587926864624,\n",
       " 'eval_accuracy': 0.43204202232435984,\n",
       " 'eval_runtime': 17.9273,\n",
       " 'eval_samples_per_second': 84.954,\n",
       " 'eval_steps_per_second': 2.677}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "traditional-audit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6090\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 382\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [382/382 09:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.364168</td>\n",
       "      <td>0.846356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.406036</td>\n",
       "      <td>0.845043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./clf/results/checkpoint-191\n",
      "Configuration saved in ./clf/results/checkpoint-191/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-191/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./clf/results/checkpoint-382\n",
      "Configuration saved in ./clf/results/checkpoint-382/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-382/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./clf/results/checkpoint-191 (score: 0.36416804790496826).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=382, training_loss=0.368179048816259, metrics={'train_runtime': 561.2325, 'train_samples_per_second': 21.702, 'train_steps_per_second': 0.681, 'total_flos': 256322584576200.0, 'train_loss': 0.368179048816259, 'epoch': 2.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lesbian-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36416804790496826,\n",
       " 'eval_accuracy': 0.8463558765594222,\n",
       " 'eval_runtime': 19.1949,\n",
       " 'eval_samples_per_second': 79.344,\n",
       " 'eval_steps_per_second': 2.501,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get post-training metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "signed-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./clf/results\n",
      "Configuration saved in ./clf/results/config.json\n",
      "Model weights saved in ./clf/results/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()  # save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nuclear-match",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./clf/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./clf/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NOT DISASTER\",\n",
      "    \"1\": \"DISASTER\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": null,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./clf/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./clf/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NOT DISASTER\",\n",
      "    \"1\": \"DISASTER\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": null,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./clf/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./clf/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /Users/sinanozdemir/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/sinanozdemir/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# make a classification pipeline\n",
    "pipe = pipeline(\"text-classification\", './clf/results', tokenizer=BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "advised-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'DISASTER', 'score': 0.962486982345581}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('this is awful. Such a terrible earthquake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12fc8d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NOT DISASTER', 'score': 0.03751305118203163},\n",
       "  {'label': 'DISASTER', 'score': 0.962486982345581}]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show scores for all classes\n",
    "pipe('this is awful. Such a terrible earthquake', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213d6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb8f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
